{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "C:\\Users\\ds13\\.bookmarks\\Diploma@RepoAnalyzer__\\repolier\\.venv_win\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
                }
            ],
            "source": "import pandas as pd\nimport torch\nfrom torch.utils.data import TensorDataset\nfrom tqdm.notebook import tqdm\nfrom transformers import BertForSequenceClassification, BertTokenizer"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Conference</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Innovation in Database Management: Computer Sc...</td>\n      <td>VLDB</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>High performance prime field multiplication fo...</td>\n      <td>ISCAS</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>enchanted scissors: a scissor interface for su...</td>\n      <td>SIGGRAPH</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Detection of channel degradation attack by Int...</td>\n      <td>INFOCOM</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Pinning a Complex Network through the Betweenn...</td>\n      <td>ISCAS</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                                               Title Conference\n0  Innovation in Database Management: Computer Sc...       VLDB\n1  High performance prime field multiplication fo...      ISCAS\n2  enchanted scissors: a scissor interface for su...   SIGGRAPH\n3  Detection of channel degradation attack by Int...    INFOCOM\n4  Pinning a Complex Network through the Betweenn...      ISCAS"
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df = pd.read_csv(\"data/title_conference.csv\")\ndf.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "\u0417\u0430\u043c\u0435\u0442\u0438\u043c, \u0447\u0442\u043e \u043a\u043b\u0430\u0441\u0441\u044b \u043d\u0435\u0441\u0431\u0430\u043b\u0430\u043d\u0441\u0438\u0440\u043e\u0432\u0430\u043d\u044b:"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "ISCAS       864\nINFOCOM     515\nVLDB        423\nWWW         379\nSIGGRAPH    326\nName: Conference, dtype: int64"
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "df.Conference.value_counts()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Encoding labels"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "{'VLDB': 0, 'ISCAS': 1, 'SIGGRAPH': 2, 'INFOCOM': 3, 'WWW': 4}"
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "possible_labels = df.Conference.unique()\n\nlabel_dict = {}\nfor index, possible_label in enumerate(possible_labels):\n    label_dict[possible_label] = index\nlabel_dict"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "df[\"label\"] = df.Conference.replace(label_dict)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Train and Vallidation Split"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "C:\\Users\\ds13\\AppData\\Local\\Temp\\ipykernel_20192\\2360066991.py:11: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  df.data_type = [\"not_set\"] * df.shape[0]\n"
                },
                {
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Title</th>\n    </tr>\n    <tr>\n      <th>Conference</th>\n      <th>label</th>\n      <th>data_type</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">INFOCOM</th>\n      <th rowspan=\"2\" valign=\"top\">3</th>\n      <th>train</th>\n      <td>438</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">ISCAS</th>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>train</th>\n      <td>734</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>130</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">SIGGRAPH</th>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>train</th>\n      <td>277</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>49</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">VLDB</th>\n      <th rowspan=\"2\" valign=\"top\">0</th>\n      <th>train</th>\n      <td>359</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">WWW</th>\n      <th rowspan=\"2\" valign=\"top\">4</th>\n      <th>train</th>\n      <td>322</td>\n    </tr>\n    <tr>\n      <th>val</th>\n      <td>57</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
                        "text/plain": "                            Title\nConference label data_type       \nINFOCOM    3     train        438\n                 val           77\nISCAS      1     train        734\n                 val          130\nSIGGRAPH   2     train        277\n                 val           49\nVLDB       0     train        359\n                 val           64\nWWW        4     train        322\n                 val           57"
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn.model_selection import train_test_split  # noqa: 402\n\nX_train, X_val, y_train, y_val = train_test_split(\n    df.index.values,\n    df.label.values,\n    test_size=0.15,\n    random_state=42,\n    stratify=df.label.values,\n)\n\ndf.data_type = [\"not_set\"] * df.shape[0]\n\ndf.loc[X_train, \"data_type\"] = \"train\"\ndf.loc[X_val, \"data_type\"] = \"val\"\n\ndf.groupby([\"Conference\", \"label\", \"data_type\"]).count()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## BertTokenizer"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
                }
            ],
            "source": "BERT_MODEL_TYPE = \"bert-base-uncased\"\n\n\ndef batch_encode_plus(data):\n    tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_TYPE, do_lower_case=True)\n\n    return tokenizer.batch_encode_plus(\n        data.Title.values,\n        # Sequences will be encoded with th especial tokens relative to their model.\n        add_special_tokens=True,\n        # Return attention mask according to specific tokenizer.\n        return_attention_mask=True,\n        pad_to_max_length=True,\n        max_length=256,  # Limit just in case.\n        return_tensors=\"pt\",  # Return pytorch compatible tensors.\n    )\n\n\ntrain_data = df[df[\"data_type\"] == \"train\"]\nencoded_data_train = batch_encode_plus(train_data)\n\nval_data = df[df[\"data_type\"] == \"val\"]\nencoded_data_val = batch_encode_plus(val_data)\n\ninput_ids_train = encoded_data_train[\"input_ids\"]\nattention_masks_train = encoded_data_train[\"attention_mask\"]\nlabels_train = torch.tensor(train_data.label.values)\n\ninput_ids_val = encoded_data_val[\"input_ids\"]\nattention_masks_val = encoded_data_val[\"attention_mask\"]\nlabels_val = torch.tensor(val_data.label.values)\n\ndataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\ndataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## BERT Pre-trained model"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "\nDownloading (\u2026)\"pytorch_model.bin\";:   0%|                                                                                                                         | 0.00/440M [00:00<?, ?B/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:   2%|\u2588\u2588\u258b                                                                                                             | 10.5M/440M [00:04<03:02, 2.36MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:   5%|\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                          | 21.0M/440M [00:08<02:59, 2.34MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:   7%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                                                        | 31.5M/440M [00:13<02:56, 2.32MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  10%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                                     | 41.9M/440M [00:18<02:56, 2.26MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  12%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                                  | 52.4M/440M [00:22<02:49, 2.29MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  14%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                                                | 62.9M/440M [00:27<02:41, 2.34MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  17%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                                             | 73.4M/440M [00:32<02:41, 2.27MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  19%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                          | 83.9M/440M [00:36<02:35, 2.30MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  21%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                                        | 94.4M/440M [00:40<02:29, 2.31MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  24%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                                      | 105M/440M [00:45<02:22, 2.35MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  26%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                                                   | 115M/440M [00:50<02:21, 2.30MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  29%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                                | 126M/440M [00:54<02:18, 2.26MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  31%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                                                              | 136M/440M [00:59<02:13, 2.28MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  33%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                           | 147M/440M [01:03<02:08, 2.29MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  36%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                                                        | 157M/440M [01:09<02:08, 2.20MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  38%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                                      | 168M/440M [01:13<02:02, 2.23MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  40%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                                                   | 178M/440M [01:18<01:55, 2.26MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  43%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                                | 189M/440M [01:22<01:49, 2.31MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  45%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                                              | 199M/440M [01:26<01:41, 2.37MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  48%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                           | 210M/440M [01:31<01:39, 2.32MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  50%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                                                        | 220M/440M [01:35<01:35, 2.31MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  52%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                                                     | 231M/440M [01:40<01:31, 2.30MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  55%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                                                   | 241M/440M [01:45<01:29, 2.24MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  57%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c                                                | 252M/440M [01:50<01:24, 2.23MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  60%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                             | 262M/440M [01:55<01:22, 2.17MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  62%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589                                           | 273M/440M [02:00<01:16, 2.20MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  64%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                        | 283M/440M [02:04<01:10, 2.24MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  67%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e                                     | 294M/440M [02:09<01:05, 2.25MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                                   | 304M/440M [02:13<01:00, 2.27MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b                                | 315M/440M [02:18<00:55, 2.25MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                             | 325M/440M [02:23<00:51, 2.25MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588                           | 336M/440M [02:27<00:46, 2.24MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                        | 346M/440M [02:32<00:42, 2.23MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d                     | 357M/440M [02:37<00:37, 2.22MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f                  | 367M/440M [02:42<00:33, 2.21MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a                | 377M/440M [02:46<00:28, 2.22MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c             | 388M/440M [02:51<00:23, 2.27MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f          | 398M/440M [02:55<00:18, 2.30MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589        | 409M/440M [03:00<00:13, 2.30MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c     | 419M/440M [03:04<00:09, 2.25MB/s]\u001b[A\nDownloading (\u2026)\"pytorch_model.bin\";:  98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 430M/440M [03:09<00:04, 2.28MB/s]\u001b[A\n"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "Downloading (\u2026)\"pytorch_model.bin\";: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 440M/440M [03:14<00:00, 2.27MB/s]\u001b[A\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                }
            ],
            "source": "model = BertForSequenceClassification.from_pretrained(\n    BERT_MODEL_TYPE,\n    num_labels=len(label_dict),\n    output_attentions=False,\n    output_hidden_states=False,\n)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Data Loaders\nLet's combine a dataset and a sampler to data loader that provides an iterable\nover the given dataset."
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler  # noqa: 402\n\nBATCH_SIZE = 3\n\ndataloader_train = DataLoader(\n    dataset_train, sampler=RandomSampler(dataset_train), batch_size=BATCH_SIZE\n)\n\ndataloader_val = DataLoader(\n    dataset_val, sampler=RandomSampler(dataset_val), batch_size=BATCH_SIZE\n)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Optimizer & Scheduler\n1. We should define parameters to optimize in iterable.\n2. Then specify optmizer-specific options such as epochs, learning_rate...\n3. Create a schedule with a learning rate that first inreases linearly from\n0 to the initial learning rate set in the optimizer (a.k.a. warm up period) and then\ndecreases linearly from the initial learning rate to 0."
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "C:\\Users\\ds13\\.bookmarks\\Diploma@RepoAnalyzer__\\repolier\\.venv_win\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n"
                }
            ],
            "source": "from transformers import AdamW, get_linear_schedule_with_warmup  # noqa: 402\n\nLEARNING_RATE = 1e-5\nEPSILON = 1e-8\nEPOCHS = 5  # Depends on dataset.\n\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=EPSILON)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, num_warmup_steps=0, num_training_steps=len(dataloader_train) * EPOCHS\n)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Performance mentrics\nWe will use f1 and accuracy per class."
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "import numpy as np  # noqa: 402\nfrom sklearn.metrics import f1_score  # noqa: 402\n\n\ndef get_f1_score(predictions, labels):\n    predictions_flattened = np.argmax(predictions, axis=1).flatten()\n    labels_flattened = labels.flatten()\n\n    return f1_score(labels_flattened, predictions_flattened, average=\"weighted\")\n\n\ndef accuracy_per_class(predictions, labels):\n    # Inverse the dictionary.\n    labels_lookup_table = {v: k for k, v in labels.items()}\n\n    predictions_flattened = np.argmax(predictions, axis=1).flatten()\n    labels_flattened = labels.flatten()\n\n    for label in np.unique(labels_flattened):\n        y_predicted = predictions[labels_flattened == label]\n        y_true = labels_flattened[labels_flattened == label]\n\n        print(f\"Class: {labels_lookup_table[label]}\")\n        print(f\"Accuracy: {len(y_predicted[y_predicted==label])}/{len(y_true)}\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Training loop"
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "cpu\n"
                }
            ],
            "source": "import random  # noqa: 402\n\nseed_val = 17\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n\nprint(device)"
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'EPOCH' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[18], line 40\u001b[0m\n\u001b[0;32m     35\u001b[0m     true_vals \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(true_vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_val_avg, predictions, true_vals\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[43mEPOCH\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m     41\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     43\u001b[0m     loss_train_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'EPOCH' is not defined"
                    ]
                }
            ],
            "source": "def get_inputs_from_batch(batch):\n    return {\n        \"input_ids\": batch[0],\n        \"attention_mask\": batch[1],\n        \"labels\": batch[2],\n    }\n\n\ndef evaluate(dataloader_val):\n    model.eval()\n\n    loss_val_total = 0\n    predictions, true_vals = [], []\n\n    for batch in dataloader_val:\n        batch = tuple(b.to(device) for b in batch)\n\n        inputs = get_inputs_from_batch(batch)\n\n        with torch.no_grad():\n            outputs = model(**inputs)\n\n        loss = outputs[0]\n        logits = outputs[1]\n        loss_val_total += loss.item()\n\n        logits = logits.detach().cpu().numpy()\n        label_ids = inputs[\"labels\"].cpu().numpy()\n        predictions.append(logits)\n        true_vals.append(label_ids)\n\n    loss_val_avg = loss_val_total / len(dataloader_val)\n\n    predictions = np.concatenate(predictions, axis=0)\n    true_vals = np.concatenate(true_vals, axis=0)\n\n    return loss_val_avg, predictions, true_vals\n\n\nfor epoch in tqdm(range(1, EPOCHS + 1)):\n    model.train()\n\n    loss_train_total = 0\n\n    progress_bar = tqdm(\n        dataloader_train, desc=\"Epoch {:1d}\".format(epoch), leave=False, disable=False\n    )\n    for batch in progress_bar:\n        model.zero_grad()\n\n        batch = tuple(b.to(device) for b in batch)\n\n        inputs = get_inputs_from_batch(batch)\n\n        outputs = model(**inputs)\n\n        loss = outputs[0]\n        loss_train_total += loss.item()\n        loss.backward()\n\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n        optimizer.step()\n        scheduler.step()\n\n        progress_bar.set_postfix(\n            {\"training_loss\": \"{:.3f}\".format(loss.item() / len(batch))}\n        )\n\n    torch.save(model.state_dict(), f\"data_volume/finetuned_BERT_epoch_{epoch}.model\")\n\n    tqdm.write(f\"\\nEpoch {epoch}\")\n\n    loss_train_avg = loss_train_total / len(dataloader_train)\n    tqdm.write(f\"Training loss: {loss_train_avg}\")\n\n    val_loss, predictions, true_vals = evaluate(dataloader_val)\n    val_f1 = get_f1_score(predictions, true_vals)\n    tqdm.write(f\"Validation loss: {val_loss}\")\n    tqdm.write(f\"F1 Score (weighted): {val_f1}\")"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
